{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from torch_tools.data import UnannotatedDataset\n",
    "from torch_tools.visualization import to_image, to_image_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Load and Data Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from models.networks import define_G, define_D\n",
    "\n",
    "\n",
    "def load_from_state(state_path):\n",
    "    state = torch.load(state_path, map_location='cpu')\n",
    "\n",
    "    gen = define_G(3, 3, 64, 'resnet_9blocks', norm='instance').cuda()\n",
    "    gen.load_state_dict(\n",
    "        {k.replace('netG.module.', ''): val for k, val in state.items()},\n",
    "        strict=False,\n",
    "    );\n",
    "\n",
    "    dis = define_D(3, 64, 'basic', norm='instance').cuda()\n",
    "    dis.load_state_dict(\n",
    "        {k.replace('netD.module.', ''): val for k, val in state.items()},\n",
    "        strict=False,\n",
    "    );\n",
    "    return gen, dis\n",
    "\n",
    "\n",
    "target_task = 'zebra2horse'\n",
    "gen, dis = load_from_state(f'checkpoints/CUT_synth_aug/{target_task}/state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_path = {\n",
    "    'summer2winter': 'datasets/summer2winter_yosemite/testA',\n",
    "    'winter2summer': 'datasets/summer2winter_yosemite/testB',\n",
    "    'apple2orange': 'datasets/apple2orange/testA',\n",
    "    'orange2apple': 'datasets/apple2orange/testB',\n",
    "    'horse2zebra': 'datasets/horse2zebra/testA',\n",
    "    'zebra2horse': 'datasets/horse2zebra/testB',\n",
    "}[target_task]\n",
    "\n",
    "\n",
    "ds_source_test = UnannotatedDataset(ds_path)\n",
    "ds_source_train = UnannotatedDataset(ds_path.replace('test', 'train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loaded Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "source = next(iter(DataLoader(ds_source_test, batch_size, shuffle=True))).cuda()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample = gen(source)\n",
    "\n",
    "to_image_grid(torch.cat([source, sample]), nrow=len(source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fid import fid\n",
    "\n",
    "def compute_img2img_fid(gen, model=None):\n",
    "    def it_gen():\n",
    "        for sample in DataLoader(ds_source_test, batch_size=16):\n",
    "            with torch.no_grad():\n",
    "                yield gen(sample.cuda())\n",
    "\n",
    "    ds_target = ds_path.replace('testA', 'testB') if 'testA' in ds_path else \\\n",
    "                ds_path.replace('testB', 'testA')\n",
    "    it_real = DataLoader(UnannotatedDataset(ds_target), batch_size=16)\n",
    "    fid_val = fid.calculate_fid_given_iterators(\n",
    "        it_gen(),\n",
    "        it_real,\n",
    "        compute_option=fid.FIDBackend.numpy,\n",
    "        verbose=True,\n",
    "        normalize_input=False,\n",
    "    )\n",
    "\n",
    "    return fid_val\n",
    "\n",
    "print(compute_img2img_fid(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StyleGAN2-ADA Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from StyleGAN2_ada.training.networks import Generator as StyleGAN2AdaGenerator\n",
    "\n",
    "\n",
    "chkpts_dir = './checkpoints/StyleGAN2_ADA'\n",
    "chkpts = os.listdir(chkpts_dir)\n",
    "samples_per_gen = 6\n",
    "fig, axs = plt.subplots(len(chkpts), 1, figsize=(2 * samples_per_gen, 2 * len(chkpts)))\n",
    "\n",
    "\n",
    "for ax, chkpt in zip(axs, chkpts):\n",
    "    G = StyleGAN2AdaGenerator(512, 0, 512, 256, 3)\n",
    "    G.load_state_dict(torch.load(f'{chkpts_dir}/{chkpt}', map_location='cpu')['G_ema'])\n",
    "    G.eval().cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        imgs_orig = G(torch.randn([samples_per_gen, 512], device='cuda'),\n",
    "                      c=None, truncation_psi=1.0)\n",
    "\n",
    "    ax.axis('off')\n",
    "    ax.set_title(chkpt)\n",
    "    ax.imshow(to_image_grid(imgs_orig))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
